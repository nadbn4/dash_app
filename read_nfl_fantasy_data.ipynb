{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re, requests, bs4, csv, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',50)\n",
    "pd.set_option('display.width',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape CBS Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxscoreScrapeWk(wkNum):\n",
    "    print(datetime.datetime.now())\n",
    "    #Scrape CBS NFL schedule for week \"wkNum\", and generate boxscore links\n",
    "    #Scrape each boxscore link from above and write to csv\n",
    "    #Ex, https://www.cbssports.com/nfl/gametracker/boxscore/NFL_20171210_IND@BUF\n",
    "\n",
    "    cbs_url = 'https://www.cbssports.com'\n",
    "    #schedule_url = cbs_url+'/nfl/schedule/2020/regular/'+str(wkNum)\n",
    "    schedule_url = '/nfl/schedule/2020/regular/'\n",
    "    \n",
    "    seasonDF = pd.DataFrame(columns=['Week','Date','Road','Home','url'])\n",
    "    # Ex, 1, YYYY-MM-DD, AWY, @HME, http://...AWY@HME/\n",
    "    \n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    for i in range(1,18):\n",
    "        weekURL = cbs_url+schedule_url+str(i)\n",
    "        wkSoup = bs4.BeautifulSoup(session.get(weekURL).text,'html.parser')\n",
    "        gameURLs = wkSoup.select('.CellGame a[href]')\n",
    "        numGm = len(gameURLs)\n",
    "        \n",
    "        #create DF of one week's games\n",
    "        thisWkDF = pd.DataFrame(columns=['Week','Date','Road','Home','url'])\n",
    "        \n",
    "        for j in range(numGm):\n",
    "            link = gameURLs[j].get('href')\n",
    "            p = link.find('NFL_')+4\n",
    "            thisWkDF.loc[j] = [i] + [str(link[p:p+4]+'-'+link[p+4:p+6]+'-'+link[p+6:p+8])]+[link[p+9:(link.find('@'))]] + [link[(link.find('@')):-1]]+[cbs_url+link] \n",
    "\n",
    "        seasonDF = seasonDF.append(thisWkDF)        \n",
    "        #del(thisWkDF)\n",
    "        #append above DF to schedDF\n",
    "        \n",
    "    gmURLs = seasonDF[seasonDF['Week']==wkNum]['url']\n",
    "    numGm = len(gmURLs)\n",
    "    print(numGm)\n",
    "    #wkSchedSoup = bs4.BeautifulSoup(requests.get(cbs_url+schedule_url+str(wkNum)).text,'html.parser')\n",
    "    #for 16 matches in i, generate dataframe, game boxscore URLs down one column\n",
    "    #numGm = len(wkSchedSoup.select('.CellGame a[href]'))\n",
    "    \n",
    "    #for i in range(numGm):\n",
    "    #    gmURLs.loc[i] = cbs_url+str(wkSchedSoup.select('.CellGame a[href]')[i].get('href')).replace('recap','boxscore')\n",
    "\n",
    "    soupOutput = []\n",
    "    tagDump = open('nflBoxscoreScrape2020(Tags)_week' + str(wkNum) + '.csv','a',newline='') #change to append\n",
    "    tagCSVWriter = csv.writer(tagDump,delimiter=',',lineterminator='\\n') #change to append\n",
    "\n",
    "    realOutput = []\n",
    "    realDump = open('nflBoxscoreScrape2020_week' + str(wkNum) + '.csv','a',newline='')\n",
    "    realCSVWriter = csv.writer(realDump,delimiter=',',lineterminator='\\n')\n",
    "    \n",
    "    #######################################################\n",
    "    ###  NEED SCHEDULE CSV BUT CAN DO FROM PANDA STRAIGHT TO CSV???\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #schdOutput = []\n",
    "    #schdDump = open('2020_schedule_single.csv','a',newline='')\n",
    "    #schdCSVWriter = csv.writer(realDump,delimiter=',',lineterminator='\\n')\n",
    "\n",
    "    seasonDF.drop('url',axis=1).to_csv('2020_schedule_single_week' + str(wkNum) + '.csv', sep = ',', encoding = 'utf-8', index = False)\n",
    "\n",
    "\n",
    "\n",
    "    #######################################################\n",
    "    \n",
    "    tagPick_lines = '.team-stats tr'\n",
    "    #tagPick_stat_feld/valu = '.team-stats td'\n",
    "    #print('\\n'+str(len(url_game))+'\\n')\n",
    "    #print(url_game[-1])\n",
    "\n",
    "    # Go through game url list and scrape each url\n",
    "    for i in range(len(gmURLs)):\n",
    "        url=str(gmURLs.loc[i])\n",
    "        boxSoup = bs4.BeautifulSoup(requests.get(url).text,'html.parser')\n",
    "\n",
    "        # TESTING: Make sure each game has 36 stats(from bs4 Object length) \n",
    "        print('Gm '+str(i)+'  '+url+'   '+str(len(boxSoup.select(tagPick_lines))))\n",
    "        print(datetime.datetime.now())\n",
    "        p = url.find('NFL_')+4\n",
    "        soupOutput.append([url[p:-1],boxSoup.select(tagPick_lines)[0].getText()])\n",
    "\n",
    "        for j in range(1,len(boxSoup.select(tagPick_lines))):\n",
    "            soupOutput[i].append(boxSoup.select(tagPick_lines)[j].getText())\n",
    "\n",
    "        tagCSVWriter.writerow(soupOutput[i])\n",
    "\n",
    "    tagDump.close()\n",
    "    \n",
    "    print('NFL Boxscore from CBS Scrape ended.')\n",
    "    #print('Example row: '+str(soupOutput[0]))   #TO SEE \\n 's\n",
    "    #print('Example row: '+soupOutput[0][35])\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    # organize soupOutput\n",
    "    nxt_rcrd = 0\n",
    "    realOutput.append(['Gm','Date','Team'])\n",
    "    for h in range(1,len(soupOutput[0])):\n",
    "        realOutput[nxt_rcrd].append(soupOutput[0][h].splitlines()[0])\n",
    "        #builds rest of column headings\n",
    "    nxt_rcrd += 1    \n",
    "\n",
    "    for i in range(len(soupOutput)):\n",
    "        url=str(gmURLs.loc[i])\n",
    "        p = url.find('NFL_')+4    \n",
    "        realOutput.append([url[p:-1],\n",
    "                           url[p:p+8],\n",
    "                           url[url.rfind('_')+1:url.find('@')]  #away team\n",
    "                           ])\n",
    "        for j in range(1,len(soupOutput[i])):\n",
    "            realOutput[nxt_rcrd].append(soupOutput[i][j].splitlines()[1])\n",
    "\n",
    "        nxt_rcrd += 1    \n",
    "\n",
    "        realOutput.append([url[p:-1],\n",
    "                           url[p:p+8],\n",
    "                           url[url.find('@')+1:len(url)-1]   #home team\n",
    "                           ])\n",
    "        for k in range(1,len(soupOutput[i])): #Do something different if j=34,35\n",
    "                                              #RZ and GoalToGo success rate had\n",
    "                                              #FIVE lines (\\n) to include %.\n",
    "            if not 33<k<36:\n",
    "                realOutput[nxt_rcrd].append(soupOutput[i][k].splitlines()[2])\n",
    "            else:\n",
    "                realOutput[nxt_rcrd].append(soupOutput[i][k].splitlines()[4])\n",
    "        nxt_rcrd += 1\n",
    "\n",
    "    # Organized soupOutput written to csv    \n",
    "    for i in (range(len(realOutput))):\n",
    "        realCSVWriter.writerow(realOutput[i])\n",
    "    realDump.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-27 07:28:24.333347\n",
      "14\n",
      "Gm 0  https://www.cbssports.com/nfl/gametracker/live/NFL_20201029_ATL@CAR/   0\n",
      "2020-10-27 07:28:44.293958\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6a04fa230690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboxscoreScrapeWk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ea40faeb161d>\u001b[0m in \u001b[0;36mboxscoreScrapeWk\u001b[1;34m(wkNum)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NFL_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0msoupOutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxSoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagPick_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxSoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagPick_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "boxscoreScrapeWk(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape ESPN Fantasy Football League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fantasy.espn.com/apis/v3/games/ffl/seasons/2020/segments/0/leagues/169073?view=mMatchup&view=mMatchupScore\n"
     ]
    }
   ],
   "source": [
    "swid      = '{F3E3A4D2-1203-4B11-BDAD-00C92AAA3F48}'\n",
    "espn_s2   = 'AECf2TISP%2BRluNYIj24%2FqkuJBHTzAa7Br0BVIoUnBhHQCygnkN7hvyvU8wIm6XAT58otHnOZW4HjyImLJ14Rk8L9%2BwObWXeIa8kCosNFNMSc79r24KSiJK9jtqUQ2V1lvIncFM1qDhV9xL7E5jnutCP9rZfiJv8h%2Bq6WNvFb4YmyHICgx3QW68obk3wqBrGrXmw0vbq2bf367%2BsuL%2BOJ2ioRnxi1yY7LgbtiJnAXSKZj7kdIGjBiCPjUHgeXzDLHPunkLchEGlOrr%2FhG1ORgOsUX'\n",
    "league_id = 169073\n",
    "season    = 2020\n",
    "week      = 16\n",
    "\n",
    "url = 'https://fantasy.espn.com/apis/v3/games/ffl/seasons/' + \\\n",
    "      str(season) + '/segments/0/leagues/' + str(league_id) + \\\n",
    "      '?view=mMatchup&view=mMatchupScore'\n",
    "\n",
    "print(url)\n",
    "\n",
    "r = requests.get(url,\n",
    "                 params={'scoringPeriodId': week},\n",
    "                 cookies={\"SWID\": swid, \"espn_s2\": espn_s2})\n",
    "d = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('matchups_week_16.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(d, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swid      = '{F3E3A4D2-1203-4B11-BDAD-00C92AAA3F48}'\n",
    "espn_s2   = 'AECf2TISP%2BRluNYIj24%2FqkuJBHTzAa7Br0BVIoUnBhHQCygnkN7hvyvU8wIm6XAT58otHnOZW4HjyImLJ14Rk8L9%2BwObWXeIa8kCosNFNMSc79r24KSiJK9jtqUQ2V1lvIncFM1qDhV9xL7E5jnutCP9rZfiJv8h%2Bq6WNvFb4YmyHICgx3QW68obk3wqBrGrXmw0vbq2bf367%2BsuL%2BOJ2ioRnxi1yY7LgbtiJnAXSKZj7kdIGjBiCPjUHgeXzDLHPunkLchEGlOrr%2FhG1ORgOsUX'\n",
    "#league_id = 169073\n",
    "#season    = 2020\n",
    "#week      = 1\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.espn.com')\n",
    "\n",
    "swid = s.cookies.get_dict()['SWID']\n",
    "\n",
    "\n",
    "league_id = 169073\n",
    "\n",
    "\n",
    "url = 'https://fantasy.espn.com/apis/v3/games/ffl/seasons/2020/segments/0/leagues/%s' %league_id\n",
    "\n",
    "\n",
    "r = requests.get(url, cookies={\"swid\": swid, \"espn_s2\": espn_s2}).json()\n",
    "\n",
    "#Get Team IDs\n",
    "teamId = {}\n",
    "for team in r['teams']:\n",
    "    teamId[team['id']] = team['location'].strip() + ' ' + team['nickname'].strip()\n",
    "\n",
    "\n",
    "#Get each team's weekly points and calculate their head-to-head records\n",
    "weeklyPoints = {}\n",
    "r = requests.get(url, cookies={\"swid\": swid}, params={\"view\": \"mMatchup\"}).json()\n",
    "\n",
    "weeklyPts = pd.DataFrame()\n",
    "for each in r['schedule']:\n",
    "    #each = r['schedule'][0]\n",
    "\n",
    "    week = each['matchupPeriodId']\n",
    "    if week >= 14:\n",
    "        continue\n",
    "\n",
    "    homeTm = teamId[each['home']['teamId']]\n",
    "    homeTmPts = each['home']['totalPoints']\n",
    "\n",
    "    try:\n",
    "        awayTm = teamId[each['away']['teamId']]\n",
    "        awayTmPts = each['away']['totalPoints']\n",
    "    except:\n",
    "        homeTmPts = 'BYE'\n",
    "        continue\n",
    "\n",
    "    temp_df = pd.DataFrame(list(zip([homeTm, awayTm], [homeTmPts, awayTmPts], [week, week])), columns=['team','pts','week'])\n",
    "\n",
    "    if homeTmPts > awayTmPts:\n",
    "        temp_df.loc[0,'win'] = 1\n",
    "        temp_df.loc[0,'loss'] = 0\n",
    "        temp_df.loc[0,'tie'] = 0\n",
    "\n",
    "        temp_df.loc[1,'win'] = 0\n",
    "        temp_df.loc[1,'loss'] = 1\n",
    "        temp_df.loc[1,'tie'] = 0\n",
    "\n",
    "    elif homeTmPts < awayTmPts:\n",
    "        temp_df.loc[0,'win'] = 0\n",
    "        temp_df.loc[0,'loss'] = 1\n",
    "        temp_df.loc[0,'tie'] = 0\n",
    "\n",
    "        temp_df.loc[1,'win'] = 1\n",
    "        temp_df.loc[1,'loss'] = 0\n",
    "        temp_df.loc[1,'tie'] = 0\n",
    "\n",
    "    elif homeTmPts == awayTmPts:\n",
    "        temp_df.loc[0,'win'] = 0\n",
    "        temp_df.loc[0,'loss'] = 0\n",
    "        temp_df.loc[0,'tie'] = 1\n",
    "\n",
    "        temp_df.loc[1,'win'] = 0\n",
    "        temp_df.loc[1,'loss'] = 0\n",
    "        temp_df.loc[1,'tie'] = 1\n",
    "\n",
    "    weeklyPts = weeklyPts.append(temp_df, sort=True).reset_index(drop=True)\n",
    "\n",
    "weeklyPts['win'] = weeklyPts.groupby(['team'])['win'].cumsum()\n",
    "weeklyPts['loss'] = weeklyPts.groupby(['team'])['loss'].cumsum()\n",
    "weeklyPts['tie'] = weeklyPts.groupby(['team'])['tie'].cumsum()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate each teams record compared to all other teams points week to week\n",
    "cumWeeklyRecord = {}   \n",
    "for week in weeklyPts[weeklyPts['pts'] > 0]['week'].unique():\n",
    "    df = weeklyPts[weeklyPts['week'] == week]\n",
    "\n",
    "    cumWeeklyRecord[week] = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        team = row['team']\n",
    "        pts = row['pts']\n",
    "        win = len(df[df['pts'] < pts])\n",
    "        loss = len(df[df['pts'] > pts])\n",
    "        tie = len(df[df['pts'] == pts])\n",
    "\n",
    "        cumWeeklyRecord[week][team] = {}\n",
    "        cumWeeklyRecord[week][team]['win'] = win\n",
    "        cumWeeklyRecord[week][team]['loss'] = loss\n",
    "        cumWeeklyRecord[week][team]['tie'] = tie-1\n",
    "\n",
    "# Combine those cumluative records to get an overall season record      \n",
    "overallRecord = {}     \n",
    "for each in cumWeeklyRecord.items():\n",
    "    for team in each[1].keys():\n",
    "        if team not in overallRecord.keys():\n",
    "            overallRecord[team] = {} \n",
    "\n",
    "        win = each[1][team]['win']\n",
    "        loss = each[1][team]['loss']\n",
    "        tie = each[1][team]['tie']\n",
    "\n",
    "        if 'win' not in overallRecord[team].keys():\n",
    "            overallRecord[team]['win'] = win\n",
    "        else:\n",
    "            overallRecord[team]['win'] += win\n",
    "\n",
    "        if 'loss' not in overallRecord[team].keys():\n",
    "            overallRecord[team]['loss'] = loss\n",
    "        else:\n",
    "            overallRecord[team]['loss'] += loss\n",
    "\n",
    "        if 'tie' not in overallRecord[team].keys():\n",
    "            overallRecord[team]['tie'] = tie\n",
    "        else:\n",
    "            overallRecord[team]['tie'] += tie\n",
    "\n",
    "\n",
    "# Little cleaning up of the data nd calculating win %\n",
    "overallRecord_df = pd.DataFrame(overallRecord).T\n",
    "overallRecord_df = overallRecord_df.rename_axis('team').reset_index()\n",
    "overallRecord_df = overallRecord_df.rename(columns={'win':'overall_win', 'loss':'overall_loss','tie':'overall_tie'})\n",
    "overallRecord_df['overall_win%'] = overallRecord_df['overall_win'] / (overallRecord_df['overall_win'] + overallRecord_df['overall_loss'] + overallRecord_df['overall_tie'])\n",
    "overallRecord_df['overall_rank'] = overallRecord_df['overall_win%'].rank(ascending=False, method='min')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regularSeasRecord = weeklyPts[weeklyPts['week'] == 13][['team','win','loss', 'tie']]\n",
    "regularSeasRecord['win%'] = regularSeasRecord['win'] / (regularSeasRecord['win'] + regularSeasRecord['loss'] + regularSeasRecord['tie'])\n",
    "regularSeasRecord['rank'] = regularSeasRecord['win%'].rank(ascending=False, method='min')\n",
    "\n",
    "\n",
    "\n",
    "final_df = overallRecord_df.merge(regularSeasRecord, how='left', on=['team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#swid      = '{F3E3A4D2-1203-4B11-BDAD-00C92AAA3F48}'\n",
    "espn_s2   = 'AECf2TISP%2BRluNYIj24%2FqkuJBHTzAa7Br0BVIoUnBhHQCygnkN7hvyvU8wIm6XAT58otHnOZW4HjyImLJ14Rk8L9%2BwObWXeIa8kCosNFNMSc79r24KSiJK9jtqUQ2V1lvIncFM1qDhV9xL7E5jnutCP9rZfiJv8h%2Bq6WNvFb4YmyHICgx3QW68obk3wqBrGrXmw0vbq2bf367%2BsuL%2BOJ2ioRnxi1yY7LgbtiJnAXSKZj7kdIGjBiCPjUHgeXzDLHPunkLchEGlOrr%2FhG1ORgOsUX'\n",
    "#league_id = 169073\n",
    "#season    = 2020\n",
    "#week      = 1\n",
    "\n",
    "\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.espn.com')\n",
    "\n",
    "swid = s.cookies.get_dict()['SWID']\n",
    "\n",
    "\n",
    "league_id = 169073\n",
    "\n",
    "\n",
    "url = 'https://fantasy.espn.com/apis/v3/games/ffl/seasons/2020/segments/0/leagues/%s' %league_id\n",
    "\n",
    "\n",
    "r = requests.get(url, cookies={\"swid\": swid, \"espn_s2\": espn_s2}).json()\n",
    "\n",
    "#Get Team IDs\n",
    "teamId = {}\n",
    "for team in r['teams']:\n",
    "    teamId[team['id']] = team['location'].strip() + ' ' + team['nickname'].strip()\n",
    "\n",
    "teamId\n",
    "#Get each team's weekly points and calculate their head-to-head records\n",
    "weeklyPoints = {}\n",
    "r = requests.get(url, cookies={\"swid\": swid}, params={\"view\": \"mMatchup\"}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('second_json_attempt.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(r, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "f = open('third_json_attempt.json') \n",
    "  \n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "data = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['stats'][5]['statSourceId'])\n",
    "print(data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['stats'][5]['appliedTotal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['stats'][2]['statSourceId'])\n",
    "print(data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['stats'][2]['appliedTotal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(data['schedule'][i]['id'])\n",
    "    #print(i.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['schedule']:\n",
    "    print(i.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"active player: \", data['schedule'][0]['away']['rosterForMatchupPeriod']['entries'][0]['playerPoolEntry']['player']['fullName'])\n",
    "print(\"actual points:\", data['schedule'][0]['away']['rosterForMatchupPeriod']['entries'][0]['playerPoolEntry']['appliedStatTotal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"player:\", data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['fullName'])\n",
    "print(\"points:\", data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['appliedStatTotal'])\n",
    "print(\"current injury status:\", data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['injuryStatus'])\n",
    "print(\"team_id:\", data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['proTeamId'])\n",
    "print(\"position_id:\", data['teams'][0]['roster']['entries'][0]['playerPoolEntry']['player']['defaultPositionId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['teams'][9]['roster']['entries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-faa5beda2f1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpro_team_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'teams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'teams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'roster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mteam_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'teams'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "team_id = []\n",
    "player = []\n",
    "points = []\n",
    "current_injury_status = []\n",
    "matchup_injury_status = []\n",
    "lineup_slot_id = []\n",
    "position_id = []\n",
    "pro_team_id = []\n",
    "\n",
    "for i in range(0, len(data['teams'])):\n",
    "    for j in range(0, len(data['teams'][i]['roster']['entries'])):\n",
    "        team_id.append(data['teams'][i]['id'])\n",
    "        player.append(data['teams'][i]['roster']['entries'][j]['playerPoolEntry']['player']['fullName'])\n",
    "        points.append(data['teams'][i]['roster']['entries'][j]['playerPoolEntry']['appliedStatTotal'])\n",
    "        #current_injury_status.append(data['teams'][i]['roster']['entries'][j]['playerPoolEntry']['player']['injuryStatus'])\n",
    "        matchup_injury_status.append(data['teams'][i]['roster']['entries'][j]['injuryStatus'])\n",
    "        lineup_slot_id.append(data['teams'][i]['roster']['entries'][j]['lineupSlotId'])\n",
    "        position_id.append(data['teams'][i]['roster']['entries'][j]['playerPoolEntry']['player']['defaultPositionId'])\n",
    "        pro_team_id.append(data['teams'][i]['roster']['entries'][j]['playerPoolEntry']['player']['proTeamId'])\n",
    "        \n",
    "rosters_df = pd.DataFrame({'team_id' : team_id, \n",
    "                           'player' : player, \n",
    "                           'points' : points, \n",
    "                           'matchup_injury_status': matchup_injury_status,\n",
    "                           #'current_injury_status' : current_injury_status,\n",
    "                           'lineup_slot_id': lineup_slot_id,\n",
    "                           'position_id' : position_id,\n",
    "                           'pro_team_id' : pro_team_id\n",
    "                          })\n",
    "\n",
    "rosters_df.loc[rosters_df['team_id'] == 1].sort_values('lineup_slot_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosters_df['pro_team_id'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosters_df.loc[rosters_df['pro_team_id'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_team_id = []\n",
    "away_team_score = []\n",
    "home_team_id = []\n",
    "home_team_score = []\n",
    "matchupPeriod = []\n",
    "winner = []\n",
    "\n",
    "week = []\n",
    "team_id = []\n",
    "opp_id = []\n",
    "score = []\n",
    "win = []\n",
    "\n",
    "\n",
    "for i in range(0, len(data['schedule'])):\n",
    "    \n",
    "    if data['schedule'][i]['away']['totalPoints'] == 0:\n",
    "        break\n",
    "        \n",
    "    # build row for away team\n",
    "    week.append(data['schedule'][i]['matchupPeriodId'])\n",
    "    team_id.append(data['schedule'][i]['away']['teamId'])\n",
    "    score.append(data['schedule'][i]['away']['totalPoints'])\n",
    "    opp_id.append(data['schedule'][i]['home']['teamId'])\n",
    "    \n",
    "    # determine if away team won\n",
    "    if data['schedule'][i]['winner'] == 'AWAY':\n",
    "        win.append(1)\n",
    "    else:\n",
    "        win.append(0)\n",
    "    \n",
    "    # build row for home team\n",
    "    week.append(data['schedule'][i]['matchupPeriodId'])\n",
    "    team_id.append(data['schedule'][i]['home']['teamId'])\n",
    "    score.append(data['schedule'][i]['home']['totalPoints'])\n",
    "    opp_id.append(data['schedule'][i]['away']['teamId'])\n",
    "    \n",
    "    # determine if home team won    \n",
    "    if data['schedule'][i]['winner'] == 'HOME':\n",
    "        win.append(1)\n",
    "    else:\n",
    "        win.append(0)\n",
    "    \n",
    "df = pd.DataFrame({'week': week, 'team_id': team_id, 'opp_id': opp_id, 'score': score, 'win': win})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(data=df, x=\"week\", y=\"score\", hue = 'team_id')\n",
    "g.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly==4.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x=\"week\", y=\"score\", color = 'team_id', title='Score per Week')\n",
    "fig.update_xaxes(range=[0.95, 5.05], dtick=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['week'].loc[(df['team_id'] == 6)], df['score'].loc[(df['team_id'] == 6)], label = 6)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 1)], df['score'].loc[(df['team_id'] == 1)], label = 1)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 2)], df['score'].loc[(df['team_id'] == 2)], label = 2)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 15)], df['score'].loc[(df['team_id'] == 15)], label = 15)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 7)], df['score'].loc[(df['team_id'] == 7)], label = 7)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 11)], df['score'].loc[(df['team_id'] == 11)], label = 11)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 4)], df['score'].loc[(df['team_id'] == 4)], label = 4)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 8)], df['score'].loc[(df['team_id'] == 8)], label = 8)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 9)], df['score'].loc[(df['team_id'] == 9)], label = 9)\n",
    "plt.plot(df['week'].loc[(df['team_id'] == 10)], df['score'].loc[(df['team_id'] == 10)], label = 10)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['team_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week'].loc[(df['team_id'] == 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file \n",
    "f = open('second_json_attempt.json') \n",
    "  \n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "data = json.load(f) \n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process FF File in weekly Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "for directory in os.listdir('weekly'):\n",
    "    \n",
    "    for sub_directory in os.listdir('weekly' + '/' + directory):\n",
    "        \n",
    "        file_list.append('weekly' + '/' + directory + '/' + sub_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ff_csv(filenames):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        dummy_df = pd.read_csv(filename)\n",
    "        dummy_df['Year'] = int(re.search(r'/(.+?)/', filename).group(1))\n",
    "        dummy_df['Week'] = int(re.search(r'\\/week(.+?)\\.', filename).group(1))\n",
    "        df = df.append(dummy_df, ignore_index = True)\n",
    "    \n",
    "    df = df[['Player', 'Pos', 'Tm', 'Year', 'Week', 'PassingYds', 'PassingTD', 'Int', 'PassingAtt', 'Cmp', 'RushingAtt', 'RushingYds', \n",
    "             'RushingTD', 'Rec', 'Tgt', 'ReceivingYds', 'ReceivingTD', 'FL', 'PPRFantasyPoints', 'StandardFantasyPoints', \n",
    "             'HalfPPRFantasyPoints']].sort_values(by = ['Year', 'Week'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_df = read_ff_csv(file_list)\n",
    "ff_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
